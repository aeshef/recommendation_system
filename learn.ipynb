{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы планируем обучать модели на алгоритмах градиентного спуска, который имеет особенно в работе с категориальными признаками. Так, создадим новый датасет для обучения, не обрабатывая числовые данные и кодируя категориальные. Для этого сначала выгрузим ранее кэшированные обработанные датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv('/Users/artemshevchenko/Desktop/ВК_рек/kkbox-music-recommendation-challenge/train_target_for_train.csv')\n",
    "test = pd.read_csv('/Users/artemshevchenko/Desktop/ВК_рек/kkbox-music-recommendation-challenge/test_for_train.csv')\n",
    "train = pd.read_csv('/Users/artemshevchenko/Desktop/ВК_рек/kkbox-music-recommendation-challenge/train_for_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.select_dtypes(include=['category']).columns\n",
    "numerical_cols = train.select_dtypes(include=['int', 'float']).columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "train_categorical_encoded = encoder.fit_transform(train[categorical_cols])\n",
    "train_encoded = np.hstack((train_categorical_encoded, train[numerical_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "max_auc = 0\n",
    "max_accuracy = 0\n",
    "max_precision = 0\n",
    "max_recall = 0\n",
    "max_f1 = 0\n",
    "\n",
    "validation_errors = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_indices, validate_indices in kf.split(train_encoded):\n",
    "    dtrain = xgb.DMatrix(train_encoded[train_indices], label=train_target.iloc[train_indices])\n",
    "    dvalid = xgb.DMatrix(train_encoded[validate_indices], label=train_target.iloc[validate_indices])\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'max_depth': 12,\n",
    "        'eta': 0.05,\n",
    "        'subsample': 0.7,\n",
    "        'lambda' : 2\n",
    "    }\n",
    "    num_round = 150\n",
    "    \n",
    "    bst = xgb.train(params, dtrain, num_round, evals=[(dvalid, 'validation')], early_stopping_rounds=10, verbose_eval=10)\n",
    "    validation_errors.append(bst.eval(dvalid))\n",
    "    \n",
    "    predictions = bst.predict(dvalid)\n",
    "    \n",
    "    auc = roc_auc_score(train_target.iloc[validate_indices], predictions)\n",
    "    accuracy = accuracy_score(train_target.iloc[validate_indices], predictions.round())\n",
    "    precision = precision_score(train_target.iloc[validate_indices], predictions.round())\n",
    "    recall = recall_score(train_target.iloc[validate_indices], predictions.round())\n",
    "    f1 = f1_score(train_target.iloc[validate_indices], predictions.round())\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    max_auc = max(max_auc, auc)\n",
    "    max_accuracy = max(max_accuracy, accuracy)\n",
    "    max_precision = max(max_precision, precision)\n",
    "    max_recall = max(max_recall, recall)\n",
    "    max_f1 = max(max_f1, f1)\n",
    "    \n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(validation_errors, marker='o')\n",
    "plt.title('Validation Error across Cross-Validation Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(accuracy_scores, marker='o', color='g')\n",
    "plt.title('Accuracy across Cross-Validation Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(f1_scores, marker='o', color='b')\n",
    "plt.title('F1 Score across Cross-Validation Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(precision_scores, marker='o', color='g')\n",
    "plt.title('Precision across Cross-Validation Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(recall_scores, marker='o', color='b')\n",
    "plt.title('Recall across Cross-Validation Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Максимальный AUC по результатам кросс-валидации равен {max_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём аналогичные преобразования на том же энкодере с тестовой выборкой, а затем протестируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categorical = test.select_dtypes(include=['category'])\n",
    "test_categorical_encoded = encoder.transform(test[categorical_cols])\n",
    "test_encoded = np.hstack((test_categorical_encoded, test[numerical_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним результаты в файл \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_encoded)\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['target'])\n",
    "predictions_df['id'] = range(len(test))\n",
    "predictions_df = predictions_df[['id', 'target']]\n",
    "predictions_df.to_csv('/Users/artemshevchenko/Desktop/ВК_рек/kkbox-music-recommendation-challenge/submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
